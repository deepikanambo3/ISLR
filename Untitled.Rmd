---
title: "Lab4"
author: "Sri Seshadri"
date: "2/4/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
```

# Best subset selection

Get Hitters data and examine.

```{r}
Hitters <- ISLR::Hitters
skimr::skim(Hitters)
dim(Hitters)
Hitters <- Hitters[complete.cases(Hitters),]
dim(Hitters)
```

```{r}
subset.selection <- leaps::regsubsets(Salary ~ ., Hitters)
summary.subset.selection <- summary(subset.selection)

subset.selection <- leaps::regsubsets(Salary ~ ., Hitters,nvmax = 19)
summary.subset.selection <- summary(subset.selection)
summary.subset.selection$adjr2

plot(summary.subset.selection$adjr2,type = "b")
points(which.max(summary.subset.selection$adjr2),summary.subset.selection$adjr2[which.max(summary.subset.selection$adjr2)],col = "red")

plot(subset.selection,scale = "bic")
```

# Forward selection

```{r}
regfit.fwd <- leaps::regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
lower.mdl <- lm(Salary ~ 1, data = Hitters)
upper.mdl <- lm(Salary ~ ., data = Hitters)
Fwd.mdl <- MASS::stepAIC(lower.mdl,scope = list(lower = formula(lower.mdl), upper = formula(upper.mdl)),direction = "forward", trace = F)

regfit.fwd.summary <- summary(regfit.fwd)
plot(regfit.fwd.summary$adjr2)
points(which.max(regfit.fwd.summary$adjr2),regfit.fwd.summary$adjr2[which.max(regfit.fwd.summary$adjr2)],col = "red")
summary(Fwd.mdl)
coef(regfit.fwd,11)
broom::tidy(Fwd.mdl)
regfit.fwd.summary$adjr2
```

```{r}
regfit.bkwd <- leaps::regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
summary(regfit.bkwd)
coef(regfit.bkwd,7)
coef(regfit.fwd,7)
coef(subset.selection,7)

# hybrid
regfit.hyb <- leaps::regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "seqrep")
regfit.hyb.summary <- summary(regfit.hyb)
coef(regfit.hyb,7)
```

```{r}
predictions <- function(object, newdata, id){
  form <- as.formula(object$call[[2]])
  modelmat <- model.matrix(form,newdata)
  coefs <- coef(object,id= id)
  modelmat[,names(coefs)] %*% coefs
}
# splits <- rsample::vfold_cv(data = Hitters)
# splits
# rsample::analysis(splits$splits$`1`)
# rsample::assessment(splits$splits$`1`)

k = 5
set.seed(1)
folds <- sample(1:k,nrow(Hitters), replace = T)
cv.errors <- matrix(NA,k, 19, dimnames = list(NULL, paste(1:19)))

for(j in 1:k){
  best.fit <- leaps::regsubsets(Salary ~ ., data = Hitters[folds !=j,], nvmax = 19)
  for (i in 1:19){
    pred = predictions(best.fit,Hitters[folds ==j,],i)
  cv.errors[j,i] <- mean((Hitters$Salary[folds==j] - pred)^2)
  }
   
}

mean.cv.errors <- apply(cv.errors, 2 ,mean)
reg.best <- leaps::regsubsets(Salary ~ ., data = Hitters, nvmax = 19)

```
# Ridge regression and lasso

```{r}
predmat <- model.matrix(Salary ~ ., Hitters)[,-1]
y = Hitters$Salary

grid = 10^seq(10,-2,length = 100)
ridge.mod <- glmnet::glmnet(predmat,y,alpha = 0,lambda = grid)
coef(ridge.mod)[,10]

predict(ridge.mod,s = 50,type = "coefficients")

set.seed(1)
train = sample(1:nrow(predmat),nrow(predmat)/2 )
test = (-train)

y.test <- y[test]

ridge.mod <- glmnet::glmnet(predmat[train,],y[train], alpha = 0, lambda = grid, thresh = 1e-12)
ridge.pred <- predict(ridge.mod,s = 50,newx = predmat[test,])
mean((ridge.pred - y.test)^2)

ridge.mod <- glmnet::glmnet(predmat[train,],y[train], alpha = 0, lambda = 0)
ridge.pred <- predict(ridge.mod,s = 0,newx = predmat[test,])
mean((ridge.pred - y.test)^2)

set.seed(1)
library(glmnet)
cv.out = cv.glmnet(predmat[train,], y[train],alpha = 0)
plot(cv.out)
bestlam <- cv.out$lambda.min
bestlam.1se <- cv.out$lambda.1se

ridge.pred <- predict(ridge.mod,s = 212, newx = predmat[test,])
mean((ridge.pred - y.test)^2)

out <- glmnet(x = predmat, y = y, alpha = 0)
predict(out,type = "coefficients", s= bestlam)
```

# Lasso
```{r}
lasso.mod <- glmnet(predmat[train,], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
```

```{r}
set.seed(1)
cv.out = cv.glmnet(predmat[train,], y[train],alpha = 1)
plot(cv.out)
lasso.pred <- predict(lasso.mod,s = cv.out$lambda.1se, newx = predmat[test,])
mean((y[test] - lasso.pred)^2)

out <- glmnet(predmat,y,alpha = 1,lambda = grid)
coefs <- predict(out,type = "coefficients", s= cv.out$lambda.1se)
```

Principal component analysis

```{r}
library(pls)
set.seed(2)
pcr.fit <- pcr(Salary ~ ., data = Hitters,scale = T,validation = "CV")
summary(pcr.fit)
```

```{r}
validationplot(pcr.fit,val.type = "MSEP",type = "b")
MSEP(pcr.fit)
```

```{r}
set.seed(1)
pcr.fit <- pcr(Salary ~ ., data = Hitters, subset = train, validation = "CV", scale = T)
validationplot(pcr.fit,val.type = "MSEP",type = "p")
```

```{r}
pcr.pred <- predict(pcr.fit,predmat[test,], ncomp = 7)
mean((y[test] - pcr.pred)^2)

pcr.fit <- pcr(Salary~., ncomp = 7, scale = T, data = Hitters)
plot(pcr.fit, ncomp=1:7)
summary(pcr.fit)
```

# Partial leas t square

```{r}
set.seed(1)
pls.fit <- plsr(Salary ~ ., data = Hitters, scale = T, validation = "CV", subset = train)
validationplot(pls.fit)
MSEP(pls.fit)
pls.pred <- predict(pls.fit,newdata = predmat[test,], ncomp = 2)
mean((pls.pred - y[test])^2)

pls.pred <- predict(pls.fit,newdata = predmat[test,], ncomp = 3)
mean((pls.pred - y[test])^2)

pls.fit <- plsr(Salary ~ ., data = Hitters, scale= T, ncomp = 3)
summary(pls.fit)
```

